
import pyodbc
import pandas as pd
import dash
from dash import dcc, html, Input, Output
import dash_bootstrap_components as dbc

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

app.layout = html.Div([
    dbc.Row([
        dbc.Col([
            dcc.Upload(
                id='upload-data',
                children=html.Div([
                    'Drag and Drop or ',
                    html.A('Select Files')
                ]),
                style={
                    'width': '100%',
                    'height': '60px',
                    'lineHeight': '60px',
                    'borderWidth': '1px',
                    'borderStyle': 'dashed',
                    'borderRadius': '5px',
                    'textAlign': 'center',
                    'margin': '10px'
                },
                multiple=True
            ),
            html.Div(id='output-data-upload'),
        ])
    ])
])


@app.callback(
    Output('output-data-upload', 'children'),
    Input('upload-data', 'contents'),
    prevent_initial_call=True
)
def update_output(content):
    if content is not None:
        content_type, content_string = content.split(',')
        decoded = base64.b64decode(content_string)
        
        # Assuming a CSV for simplicity, but you can handle other types like JSON, txt, etc.
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        
        # Create a temporary table in BigQuery
        cursor.execute("""
            CREATE TEMPORARY TABLE your_temp_table_name (
                record_id INT64
            )
        """)
        
        # Insert data from DataFrame into BigQuery
        for index, row in df.iterrows():
            cursor.execute("INSERT INTO your_temp_table_name (record_id) VALUES (?)", row['record_id'])
        
        return 'File uploaded and data stored in BigQuery temporary table!'

    return None


if __name__ == '__main__':
    app.run_server(debug=True)
